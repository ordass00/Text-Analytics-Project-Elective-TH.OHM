{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complimentary-communications",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T17:28:12.230459Z",
     "start_time": "2021-06-06T17:27:56.975124Z"
    }
   },
   "source": [
    "# Aufbereitung der Daten\n",
    "\n",
    "Um aus den im [vorherigen Kapitel](./00_Scraping_Crawling_Beitraege_Kommentare.ipynb) gescrapten Daten nun aufschlussreiche Analysen erstellen und Informationen extrahieren zu können, müssen diese jedoch erst aufbereitet werden. Im Folgenden werden also Texte durch das Entfernen von störendem Rauschen in eine saubere Form verwandelt.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "killing-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:52:37.282578Z",
     "start_time": "2021-06-20T14:52:26.575523Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-conjunction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:52:43.139433Z",
     "start_time": "2021-06-20T14:52:42.511089Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ideal-hepatitis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:52:46.144027Z",
     "start_time": "2021-06-20T14:52:45.959496Z"
    }
   },
   "outputs": [],
   "source": [
    "def pd_read_sql(database, sql):\n",
    "    with sqlite3.connect(database) as con:\n",
    "        dataframe = pd.read_sql_query(sql, con)\n",
    "        return dataframe\n",
    "\n",
    "def pd_write_sql(database, table, df):\n",
    "    with sqlite3.connect(database) as con:\n",
    "        df.to_sql(table, con, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compound-engagement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:52:50.491610Z",
     "start_time": "2021-06-20T14:52:48.289580Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd_read_sql(\"data.sqlite\", \"SELECT * FROM comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-eligibility",
   "metadata": {},
   "source": [
    "Wie man hier schön erkennen kann, enthält der DataFrame in der Spalte \"body\" die rohen, unaufbereiteten Daten mit störendem Rauschen und Artefakten wie Links, \">\"-Zeichen und \"\\n\" (Zeilenumbrüche) oder ähnlichem, die für die Analysen erstmal wenig nützlich sind. \n",
    "Diese gilt es im Folgenden nun zu bereinigen.\n",
    "\n",
    "Wir verwenden hier [spaCy](https://spacy.io/), die eine NLP Pipeline mit Verarbeitungskomponenten wie einen Tokenizer, einen Tagger, einen Parser und einen NER-Detektor zur Verfügung stellt. Da wir uns aber bei unserer Cyberpunk Analyse auf die Meinung der Nutzer zum Spiel an sich und nicht auf die Klassifikation von vordefinierten Kategorien wie z.B. Personennamen, Organisationen, Orte und andere im Spiel vorkommende Entitäten fokussieren wollen, arbeiten wir ohne die NER- und Parser-Komponente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-pacific",
   "metadata": {},
   "source": [
    "<div><img src=\"https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg\" width=\"600\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-contributor",
   "metadata": {},
   "source": [
    "Um die Verarbeitung auf der GPU laufen zu lassen (falls vorhanden), wird spaCy instruiert, dies auch zu tun. Falls nicht, wird automatisch die CPU verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "threaded-reconstruction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:52:58.432984Z",
     "start_time": "2021-06-20T14:52:54.095264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1f05a127630>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1f04607f220>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1f06edaaa00>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1f06edaa100>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if spacy.prefer_gpu():\n",
    "    print(\"Working on GPU.\")\n",
    "else:\n",
    "    print(\"No GPU found, working on CPU.\")\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-contest",
   "metadata": {},
   "source": [
    "Zitiert man einen Reddit Kommentar, entsteht im Markdown ein \">\" Zeichen. Da aber dieses Zeichen ebenso im Text als Vergleichszeichen vorkommen kann, markieren wir das Zeichen als Satzzeichen, um es so herausfiltern zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bigger-kansas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:01.740453Z",
     "start_time": "2021-06-20T14:53:01.547968Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab['>'].is_punct = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-entrance",
   "metadata": {},
   "source": [
    "Im Folgenden definieren wir nun eine Funktion, welche Texte übergeben bekommt und mit regulären Ausdrücken nach Unreinheiten sucht und diese ersetzt. So werden beispielsweise Links auf andere Beiträge und unnötige Zeichen effektiv herausgefiltert.\n",
    "\n",
    "\n",
    "Mit der zweiten Funktion ist es möglich, nachdem wir mit der NLP-Pipeline aus einem Text ein `doc`-Objekt erzeugt haben, die entsprechenden Eigenschaften der Tokens mitsamt den Attributen darzustellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fresh-harmony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:03.535909Z",
     "start_time": "2021-06-20T14:53:03.347078Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove * character\n",
    "    text = re.sub(r'\\*', '', text)\n",
    "    # remove . or ... characters\n",
    "    text = re.sub(r'\\.+', '', text)\n",
    "    #remove links like (https:...) or https:....\n",
    "    text = re.sub(r'\\(*https:[^\\\\(\\)\\n ]*\\)*', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def display_nlp(doc, include_punct=False):\n",
    "    \"\"\"Generate data frame for visualization of spaCy tokens.\"\"\"\n",
    "    rows = []\n",
    "    for i, t in enumerate(doc):\n",
    "        if not t.is_punct or include_punct:\n",
    "            row = {'token': i,  'text': t.text, 'lemma_': t.lemma_,\n",
    "                   'is_stop': t.is_stop, 'is_punct': t.is_punct,\n",
    "                   'pos_': t.pos_, 'morph': t.morph}\n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows).set_index('token')\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-product",
   "metadata": {},
   "source": [
    "Folglich wird neben der body-Spalte, welche den Rohtext enthält, eine weitere Spalte erstellt, die die bereinigten Texte erfasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transsexual-registrar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:18.655651Z",
     "start_time": "2021-06-20T14:53:08.342482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbcf8a9efd74b66a9e7f7b89b2c6ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.insert(3, 'clean_body', '')\n",
    "df['clean_body'] = df['body'].progress_map(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-wound",
   "metadata": {},
   "source": [
    "Vergleicht man nun die body-Spalte mit der clean_body-Spalte, kann man bereits einen signifikanten Unterschied erkennen: Die Leserlichkeit hat sich um einiges verbessert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "premium-installation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:20.823453Z",
     "start_time": "2021-06-20T14:53:20.431779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>clean_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109584</th>\n",
       "      <td>Feels like GTA meets Deus ex to me. Driving missions and delivery missions are so gta</td>\n",
       "      <td>Feels like GTA meets Deus ex to me Driving missions and delivery missions are so gta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179906</th>\n",
       "      <td>Yakuza minigame ♥</td>\n",
       "      <td>Yakuza minigame ♥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41782</th>\n",
       "      <td>Hey it's how Bethesda's operated for the past 15 some-odd years.</td>\n",
       "      <td>Hey it's how Bethesda's operated for the past 15 some-odd years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43937</th>\n",
       "      <td>Bruh that sucks</td>\n",
       "      <td>Bruh that sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43403</th>\n",
       "      <td>Isn't pokemon a triple A open world RPG too?</td>\n",
       "      <td>Isn't pokemon a triple A open world RPG too?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         body  \\\n",
       "109584  Feels like GTA meets Deus ex to me. Driving missions and delivery missions are so gta   \n",
       "179906                                                                      Yakuza minigame ♥   \n",
       "41782                        Hey it's how Bethesda's operated for the past 15 some-odd years.   \n",
       "43937                                                                         Bruh that sucks   \n",
       "43403                                            Isn't pokemon a triple A open world RPG too?   \n",
       "\n",
       "                                                                                  clean_body  \n",
       "109584  Feels like GTA meets Deus ex to me Driving missions and delivery missions are so gta  \n",
       "179906                                                                     Yakuza minigame ♥  \n",
       "41782                        Hey it's how Bethesda's operated for the past 15 some-odd years  \n",
       "43937                                                                        Bruh that sucks  \n",
       "43403                                           Isn't pokemon a triple A open world RPG too?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"body\", \"clean_body\"]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-monday",
   "metadata": {},
   "source": [
    "Um die NLP-Pipeline zu demonstrieren, wird hier ein Beispieltext aus der Spalte \"clean_body\" geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personal-clerk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:23.273987Z",
     "start_time": "2021-06-20T14:53:23.084465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Broken down? Watch the video again, and even if, then just driving away is still ab big asshole move'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"clean_body\"].sample().iloc[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-terror",
   "metadata": {},
   "source": [
    "Durch die NLP-Pipeline wird, wie oben beschrieben, ein Doc-Objekt erzeugt, dessen Eigenschaften mit Hilfe der `display_nlp` Funktion ausgegeben werden. \n",
    "  * text: der originale Text\n",
    "  * lemma_: grammatikalische Grundform\n",
    "  * is_stop: Flag, ob Stopp-Wort\n",
    "  * is_punct: Flag, ob Satzzeichen\n",
    "  * pos_: Part-of-Speech-Tag\n",
    "  * morph: Weitere morphologische Eigenschaften"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naughty-central",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:33.495952Z",
     "start_time": "2021-06-20T14:53:26.203496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>pos_</th>\n",
       "      <th>morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Broken</td>\n",
       "      <td>break</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Aspect=Perf, Tense=Past, VerbForm=Part)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Watch</td>\n",
       "      <td>watch</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>(Definite=Def, PronType=Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>video</td>\n",
       "      <td>video</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>again</td>\n",
       "      <td>again</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>(ConjType=Cmp)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>even</td>\n",
       "      <td>even</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>if</td>\n",
       "      <td>if</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>then</td>\n",
       "      <td>then</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>(PronType=Dem)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>just</td>\n",
       "      <td>just</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>driving</td>\n",
       "      <td>drive</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Aspect=Prog, Tense=Pres, VerbForm=Part)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>away</td>\n",
       "      <td>away</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, VerbForm=Fin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>still</td>\n",
       "      <td>still</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>big</td>\n",
       "      <td>big</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>asshole</td>\n",
       "      <td>asshole</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>move</td>\n",
       "      <td>move</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text   lemma_  is_stop  is_punct   pos_  \\\n",
       "0    Broken    break    False     False   VERB   \n",
       "1      down     down     True     False    ADP   \n",
       "3     Watch    watch    False     False   VERB   \n",
       "4       the      the     True     False    DET   \n",
       "5     video    video    False     False   NOUN   \n",
       "6     again    again     True     False    ADV   \n",
       "8       and      and     True     False  CCONJ   \n",
       "9      even     even     True     False    ADV   \n",
       "10       if       if     True     False  SCONJ   \n",
       "12     then     then     True     False    ADV   \n",
       "13     just     just     True     False    ADV   \n",
       "14  driving    drive    False     False   VERB   \n",
       "15     away     away    False     False    ADV   \n",
       "16       is       be     True     False   VERB   \n",
       "17    still    still     True     False    ADV   \n",
       "18       ab       ab    False     False    ADJ   \n",
       "19      big      big    False     False    ADJ   \n",
       "20  asshole  asshole    False     False   NOUN   \n",
       "21     move     move     True     False   VERB   \n",
       "\n",
       "                                                          morph  \n",
       "0                      (Aspect=Perf, Tense=Past, VerbForm=Part)  \n",
       "1                                                            ()  \n",
       "3                                                (VerbForm=Inf)  \n",
       "4                                  (Definite=Def, PronType=Art)  \n",
       "5                                                 (Number=Sing)  \n",
       "6                                                            ()  \n",
       "8                                                (ConjType=Cmp)  \n",
       "9                                                            ()  \n",
       "10                                                           ()  \n",
       "12                                               (PronType=Dem)  \n",
       "13                                                           ()  \n",
       "14                     (Aspect=Prog, Tense=Pres, VerbForm=Part)  \n",
       "15                                                           ()  \n",
       "16  (Mood=Ind, Number=Sing, Person=3, Tense=Pres, VerbForm=Fin)  \n",
       "17                                                           ()  \n",
       "18                                                 (Degree=Pos)  \n",
       "19                                                 (Degree=Pos)  \n",
       "20                                                (Number=Sing)  \n",
       "21                                               (VerbForm=Inf)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "display_nlp(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-preserve",
   "metadata": {},
   "source": [
    "## Aufbereitung aller Redditkommentare ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-affect",
   "metadata": {},
   "source": [
    "Nun kann die massenhafte Aufbereitung der Redditkommentare beginnen. Dafür definieren wir uns eine Funktion, mit der wir die Token nach bestimmten Eigenschaften einfach aus dem Doc-Objekt extrahieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blind-fundamental",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:37.912587Z",
     "start_time": "2021-06-20T14:53:37.734967Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc, **kwargs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-damage",
   "metadata": {},
   "source": [
    "Da wir bei unserer Analyse zu Cyperpunk 2077 speziell die User-Meinung zum Spiel untersuchen möchten, sind vorallem Adjektive und Verben zur Bestimmung des Sentiments ([siehe Notebook 03 Sentiment Analyse und Topic Analyse](./03_Sentiment_und_Topic_Analyse.ipynb)) von großer Bedeutung.\n",
    "\n",
    "Deshalb werden durch die `extract_nlp` Funktion Lemmas jeweils in eine Spalte für Adjektive/Verben, Nomen und Lemmas aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriented-marriage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:39.766532Z",
     "start_time": "2021-06-20T14:53:39.581020Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_nlp(doc):\n",
    "    return {\n",
    "    'lemmas'     : extract_lemmas(doc,exclude_pos = ['PART', 'PUNCT', 'DET', 'PRON', 'SYM', 'SPACE'], filter_stops = False),\n",
    "    'adjs_verbs' : extract_lemmas(doc, include_pos = ['ADJ', 'VERB']),\n",
    "    'nouns'      : extract_lemmas(doc, include_pos = ['NOUN', 'PROPN']),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-rover",
   "metadata": {},
   "source": [
    "Angewendet auf einen Beispielkommentar wird der Text wie folgt aufgeteilt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developing-planet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:41.575372Z",
     "start_time": "2021-06-20T14:53:41.366499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nope, im playing in vr in front of a green screen 24/7, try again\n",
      "\n",
      "{'adjs_verbs': ['m', 'play', 'green', 'try'],\n",
      " 'lemmas': ['nope',\n",
      "            'm',\n",
      "            'play',\n",
      "            'in',\n",
      "            'vr',\n",
      "            'in',\n",
      "            'front',\n",
      "            'of',\n",
      "            'green',\n",
      "            'screen',\n",
      "            '24/7',\n",
      "            'try',\n",
      "            'again'],\n",
      " 'nouns': ['vr', 'screen']}\n"
     ]
    }
   ],
   "source": [
    "text_example = df.sample(1)[\"clean_body\"].iloc[0]\n",
    "print(text_example+\"\\n\")\n",
    "\n",
    "doc_example = nlp(text_example)\n",
    "pp.pprint(extract_nlp(doc_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "australian-listing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:44.219147Z",
     "start_time": "2021-06-20T14:53:44.022646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>pos_</th>\n",
       "      <th>morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nope</td>\n",
       "      <td>nope</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>(Case=Nom, Number=Sing, Person=1, PronType=Prs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Tense=Pres, VerbForm=Fin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playing</td>\n",
       "      <td>play</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Aspect=Prog, Tense=Pres, VerbForm=Part)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vr</td>\n",
       "      <td>vr</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>front</td>\n",
       "      <td>front</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>(Definite=Ind, PronType=Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>(Degree=Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>screen</td>\n",
       "      <td>screen</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24/7</td>\n",
       "      <td>24/7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NUM</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>try</td>\n",
       "      <td>try</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>again</td>\n",
       "      <td>again</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  lemma_  is_stop  is_punct  pos_  \\\n",
       "0      nope    nope    False     False  INTJ   \n",
       "2         i       I     True     False  PRON   \n",
       "3         m       m    False     False  VERB   \n",
       "4   playing    play    False     False  VERB   \n",
       "5        in      in     True     False   ADP   \n",
       "6        vr      vr    False     False  NOUN   \n",
       "7        in      in     True     False   ADP   \n",
       "8     front   front     True     False  NOUN   \n",
       "9        of      of     True     False   ADP   \n",
       "10        a       a     True     False   DET   \n",
       "11    green   green    False     False   ADJ   \n",
       "12   screen  screen    False     False  NOUN   \n",
       "13     24/7    24/7    False     False   NUM   \n",
       "15      try     try    False     False  VERB   \n",
       "16    again   again     True     False   ADV   \n",
       "\n",
       "                                              morph  \n",
       "0                                                ()  \n",
       "2   (Case=Nom, Number=Sing, Person=1, PronType=Prs)  \n",
       "3                        (Tense=Pres, VerbForm=Fin)  \n",
       "4          (Aspect=Prog, Tense=Pres, VerbForm=Part)  \n",
       "5                                                ()  \n",
       "6                                     (Number=Sing)  \n",
       "7                                                ()  \n",
       "8                                     (Number=Sing)  \n",
       "9                                                ()  \n",
       "10                     (Definite=Ind, PronType=Art)  \n",
       "11                                     (Degree=Pos)  \n",
       "12                                    (Number=Sing)  \n",
       "13                                   (NumType=Card)  \n",
       "15                                   (VerbForm=Inf)  \n",
       "16                                               ()  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_nlp(doc_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-trigger",
   "metadata": {},
   "source": [
    "Jetzt haben wir alle Funktionen deklariert, um die massenhafte Datenaufbereitung für all unsere gescrapten Redditkommentare zu starten.\n",
    "\n",
    "Dafür legen wir zuerst die zusätzlichen Spalten in unserem Ziel-DataFrame an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "right-dakota",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T14:53:46.738994Z",
     "start_time": "2021-06-20T14:53:46.552893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemmas', 'adjs_verbs', 'nouns']\n"
     ]
    }
   ],
   "source": [
    "nlp_columns = list(extract_nlp(nlp.make_doc('')).keys())\n",
    "print(nlp_columns)\n",
    "\n",
    "for col in nlp_columns:\n",
    "    df[col] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-cameroon",
   "metadata": {},
   "source": [
    "**Achtung:** Die Aufbereitung der insgesamt knapp 442.000 Kommentare kann je nach Hardware bis zu 2 Stunden brauchen. Folgender Abschnitt kann also übersprungen werden, da die fertig aufbereiteten Kommentare bereits in der Datenbank gespeichert sind. Weiter geht es dann mit [Kapitel 02 Explorative Datenanalyse](./02_Explorative_Datenanalyse.ipynb).\n",
    "\n",
    "Wir verarbeiten im Folgenden jeweils 100 Datensätze der Redditkommentare auf einmal und fügen die extrahierten Lemmas jeweils an das Ende des Dataframes an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "invalid-holocaust",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T16:30:18.910577Z",
     "start_time": "2021-06-20T14:53:48.892235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf185180cfa4ba289c505361f083ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4415 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_batches = math.ceil(len(df) / batch_size)\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size), total=num_batches):\n",
    "    \n",
    "    # spaCy Batch-Verarbeitung mit nlp.pipe, liefert eine Liste von Ergebnis-Docs\n",
    "    docs = nlp.pipe(df['clean_body'][i:i+batch_size])\n",
    "    \n",
    "    # Extraktion der Lemmas und Eintragen im DataFrame für einen Batch\n",
    "    for j, doc in enumerate(docs):\n",
    "        for col, values in extract_nlp(doc).items():\n",
    "            df[col].iloc[i+j] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "applied-program",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T16:30:27.200102Z",
     "start_time": "2021-06-20T16:30:23.146874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c22d37a0b747499b6afb9afa039180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df5b2f8ed1b47d9a91f852a6ca0b272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f469f1a9e3a47ad93600f01b08a3785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmas</th>\n",
       "      <th>adjs_verbs</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post have receive multiple report and have be tempoarily remove until moderator can review be bot and action be perform automatically please contact moderator of subreddit if have question or concern</td>\n",
       "      <td>receive multiple remove review perform contact</td>\n",
       "      <td>post report moderator bot action moderator subreddit question concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ahhhh plan bet will go great</td>\n",
       "      <td>bet great</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just fire up rdr2 again few day ago and have same thought great game</td>\n",
       "      <td>fire great</td>\n",
       "      <td>rdr2 day thought game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remember when CD Projekt Red say that cyberpunk 2077 would be as polished as Red Dead redemption 2 sadly know be true statement</td>\n",
       "      <td>remember say polished know true</td>\n",
       "      <td>CD Projekt Red cyberpunk Red Dead redemption statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just way npc mindlessly exist in cyberpunk completely ruin for and ’ idea be make NPC outfit 100 lime green neon jumpsuit outfit stand out like crazy when ’ 17 people and 11 of be wear same exact ...</td>\n",
       "      <td>exist ruin green stand crazy wear exact implement enjoy static look</td>\n",
       "      <td>way npc cyberpunk idea NPC outfit lime neon jumpsuit outfit people outfit quest system cyberpunkI gunplay world game life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    lemmas  \\\n",
       "0  post have receive multiple report and have be tempoarily remove until moderator can review be bot and action be perform automatically please contact moderator of subreddit if have question or concern   \n",
       "1                                                                                                                                                                             ahhhh plan bet will go great   \n",
       "2                                                                                                                                     just fire up rdr2 again few day ago and have same thought great game   \n",
       "3                                                                          remember when CD Projekt Red say that cyberpunk 2077 would be as polished as Red Dead redemption 2 sadly know be true statement   \n",
       "4  just way npc mindlessly exist in cyberpunk completely ruin for and ’ idea be make NPC outfit 100 lime green neon jumpsuit outfit stand out like crazy when ’ 17 people and 11 of be wear same exact ...   \n",
       "\n",
       "                                                            adjs_verbs  \\\n",
       "0                       receive multiple remove review perform contact   \n",
       "1                                                            bet great   \n",
       "2                                                           fire great   \n",
       "3                                      remember say polished know true   \n",
       "4  exist ruin green stand crazy wear exact implement enjoy static look   \n",
       "\n",
       "                                                                                                                       nouns  \n",
       "0                                                      post report moderator bot action moderator subreddit question concern  \n",
       "1                                                                                                                       plan  \n",
       "2                                                                                                      rdr2 day thought game  \n",
       "3                                                                     CD Projekt Red cyberpunk Red Dead redemption statement  \n",
       "4  way npc cyberpunk idea NPC outfit lime neon jumpsuit outfit people outfit quest system cyberpunkI gunplay world game life  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in nlp_columns:\n",
    "    df[column] = df[column].progress_map(lambda tokens: \" \".join(tokens))\n",
    "df[nlp_columns].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-protest",
   "metadata": {},
   "source": [
    "Letztlich bleibt nur noch das Speichern des erzeugten DataFrames in der Tabelle `comments_prepared` in der Datenbank`data.sqlite` übrig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "filled-fitting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T16:30:33.887519Z",
     "start_time": "2021-06-20T16:30:30.223421Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd_write_sql(\"data.sqlite\", \"comments_prepared\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-murray",
   "metadata": {},
   "source": [
    "## Quellen ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-warrior",
   "metadata": {},
   "source": [
    "* https://spacy.io/\n",
    "* https://spacy.io/usage/processing-pipelines\n",
    "* https://spacy.io/usage/linguistic-features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
